> **AI-Generated Documentation**  
> This README was generated by AI. For questions, clarifications, or detailed information about this project, please contact: **wandahou96@gmail.com**

# 2D Quantum Machine Learning Project

A comprehensive quantum machine learning project that implements an end-to-end pipeline for quantum state prediction and reconstruction in 2D quantum systems. The project combines real quantum hardware experiments, transformer-based machine learning, and quantum state decoding to study quantum information in both single-qubit and two-qubit systems with varying experimental configurations.

## Project Overview

This project develops and demonstrates a complete quantum machine learning pipeline with **two distinct experimental paradigms**:

### Two-Probe Experiments
Studies quantum entanglement and correlations between **two probe qubits** with varying spatial separations (d=3,4,5,6) on 6×6 qubit grids. Includes transformer-based machine learning for quantum state prediction.

### Single-Probe Experiments  
Investigates quantum information properties of **individual probe qubits** within cluster states, focusing on single-qubit quantum state reconstruction and tomography.

Both experiments share four main pipeline components:

1. **Data Collection**: Experimental data generation on Google Quantum AI processors
2. **Training**: Transformer-based quantum state prediction (two-probe only)
3. **Decoding**: Quantum state reconstruction and analysis
4. **Simulation**: Classical simulation and theoretical validation (two-probe only)

## Key Features

- **Real quantum hardware integration**: Direct data collection from Google Quantum AI Willow processors
- **Transformer-based learning**: Modified Llama architecture for quantum state prediction
- **Multi-scale analysis**: Support for different probe qubit separations and system sizes
- **Comprehensive metrics**: Quantum-specific evaluation (Cross Entropy, Negativity, Entanglement Entropy)
- **Full pipeline**: From raw quantum measurements to trained ML models
- **Professional implementation**: Robust checkpointing, reproducibility, and error handling

## Project Structure

```
2d/
├── two_probes/           # Two-probe qubit experiments
│   ├── data_collection/  # Quantum hardware data generation
│   ├── training/         # ML training pipeline  
│   ├── decode/           # Quantum state reconstruction
│   └── simulation/       # Classical simulation & theory
├── single_probe/         # Single-probe qubit experiments
│   ├── data_collection/  # Quantum hardware data generation
│   ├── decode/           # Quantum state reconstruction
│   └── post_process_single.ipynb  # Data preprocessing
└── README.md            # This file
```

## Component Overview

## Two-Probe Experiments (`two_probes/`)

### 1. Data Collection (`two_probes/data_collection/`)

**Purpose**: Generate experimental quantum measurement data for two-probe qubit systems

**Key Files**:
- `data_collect.ipynb`: Main data collection notebook for Google Quantum AI processors
- `shallow_cirq_6x6_pink.py`: Quantum circuit generation for 6×6 grid systems

**Hardware**: Google Quantum AI Willow processors
- **Willow Pink** (`WLA1HHPR00V02_4A_PINK`): Used for d=3,4,5 data collection
- **Willow Delphi** (`WIL01_3A_DELPHI`): Used for d=6 data collection

**Features**:
- Two probe qubits with variable spatial separations (d=3,4,5,6)
- Randomized compiling for error mitigation
- Batch processing for efficient data collection
- Systematic parameter sweeps (theta, phi, basis states)
- Professional data organization and storage

**Output**: Raw quantum measurement sequences organized by parameters:
```
data/{snapshot_id}_d={d}/theta{theta_idx}/loop{i}/theta={theta_idx}_({b1},{b2}).pt
```

### 2. Training (`two_probes/training/`)

**Purpose**: Train transformer models to predict two-qubit quantum density matrices from measurement sequences

**Key Files**:
- `train_models.ipynb`: Main training pipeline
- `TFM.py`: Custom Llama-based transformer architecture
- `utils.py`: Quantum-specific utilities and metrics
- `post_process_d=*.ipynb`: Data preprocessing

**Architecture**: 
- Modified Llama transformer (36 layers, 96 embedding dims, 48 attention heads)
- Custom output layer for 4×4 complex density matrices (two-qubit systems)
- Attention masks for different spatial configurations
- ~2.3M parameters optimized for quantum data

**Training Features**:
- Comprehensive checkpointing (20 per epoch)
- Quantum-specific loss functions and metrics
- Reproducible train/test splits
- Real-time performance monitoring
- Memory-efficient batched processing

**Metrics**: Quantum-Classical Cross Entropy, Negativity, Von Neumann Entropy

### 3. Decode (`two_probes/decode/`)

**Purpose**: Reconstruct and analyze two-qubit quantum states from experimental data

**Key Files**:
- `decode_6x6_d={3,4,5,6}.ipynb`: State reconstruction for different separations

**Features**:
- Tensor network contraction for two-qubit state reconstruction
- Support for different probe qubit spatial configurations (d=3,4,5,6)
- Depolarization channel modeling
- Quantum state tomography analysis
- Performance evaluation across spatial scales

**Applications**:
- Two-qubit quantum state verification
- Entanglement characterization between probe qubits
- Error analysis and correction
- Experimental validation

### 4. Simulation (`two_probes/simulation/`)

**Purpose**: Classical simulation and theoretical calculations for two-probe system validation

**Key Files**:
- `cluster_simulation.ipynb`: 2D cluster state simulation
- `*.pt` files: Precomputed simulation data for different configurations

**Features**:
- 2D shallow quantum circuit simulation
- Exact quantum state evolution
- Entanglement measures (Negativity, Von Neumann Entropy)
- Theoretical benchmarks for experimental validation
- Support for various system sizes and parameters

**Output**: Theoretical predictions for comparison with experimental results

## Single-Probe Experiments (`single_probe/`)

### 1. Data Collection (`single_probe/data_collection/`)

**Purpose**: Generate experimental quantum measurement data for single-probe qubit systems

**Key Files**:
- `data_collect.ipynb`: Main data collection notebook for single probe experiments
- `shallow_cirq.py`: Quantum circuit generation for single-probe configurations

**Hardware**: Google Quantum AI Willow processors

**Features**:
- Single probe qubit measurements within cluster states
- Support for different grid sizes (3×3, 5×5, 6×6)
- Ancilla-assisted error mitigation
- Post-selection protocols for data quality
- Systematic parameter sweeps (theta values)

**Output**: Raw quantum measurement sequences for single-probe analysis

### 2. Data Processing (`single_probe/`)

**Key Files**:
- `post_process_single.ipynb`: Data preprocessing and quality filtering

**Features**:
- Post-selection based on ancilla measurements
- Shadow state reconstruction from single-qubit measurements
- Data quality filtering and validation
- Batch processing for large datasets

### 3. Decode (`single_probe/decode/`)

**Purpose**: Reconstruct and analyze single-qubit quantum states from experimental data

**Key Files**:
- `decode_6x6_single.ipynb`: Single-qubit state reconstruction and sensitivity analysis
- `post_select_radius_single.ipynb`: Post-selection analysis for different radii

**Features**:
- Tensor network contraction for single-qubit state reconstruction
- Sensitivity testing through measurement outcome flipping
- Robustness analysis against measurement errors
- Single-qubit quantum state tomography
- Post-selection radius optimization

**Applications**:
- Single-qubit quantum state verification
- Measurement error sensitivity analysis
- Algorithm robustness testing
- Single-probe quantum information studies

## Quick Start

### Prerequisites
```bash
pip install torch>=2.0.0 transformers>=4.30.0 numpy>=1.21.0 matplotlib>=3.5.0 jupyter>=1.0.0 tqdm>=4.64.0
```

### Basic Workflow

#### Two-Probe Experiments

1. **Data Collection** (requires Google Quantum AI access):
```bash
cd two_probes/data_collection/
jupyter notebook data_collect.ipynb
```

2. **Data Preprocessing**:
```bash
cd ../training/
jupyter notebook post_process_d=3,4,5.ipynb
```

3. **Model Training**:
```bash
jupyter notebook train_models.ipynb
```

4. **State Decoding**:
```bash
cd ../decode/
jupyter notebook decode_6x6_d=5.ipynb
```

5. **Analysis & Validation**:
```bash
cd ../simulation/
jupyter notebook cluster_simulation.ipynb
```

#### Single-Probe Experiments

1. **Data Collection** (requires Google Quantum AI access):
```bash
cd single_probe/data_collection/
jupyter notebook data_collect.ipynb
```

2. **Data Preprocessing**:
```bash
cd ../
jupyter notebook post_process_single.ipynb
```

3. **State Decoding & Analysis**:
```bash
cd decode/
jupyter notebook decode_6x6_single.ipynb
jupyter notebook post_select_radius_single.ipynb
```

### Data Access

**Google Drive**: https://drive.google.com/drive/folders/1mW342CtuutjiGhPIPRSAz8-r8XKolCJk?usp=sharing

**Access Request**: Email wandahou96@gmail.com with your Gmail address

## Technical Details

### Quantum System

#### Two-Probe Experiments
- **Grid**: 6×6 qubit arrays on superconducting processors
- **Processors**: 
  - Willow Pink (`WLA1HHPR00V02_4A_PINK`) for d=3,4,5
  - Willow Delphi (`WIL01_3A_DELPHI`) for d=6
- **Probe qubits**: Two-qubit systems with variable separation (d=3,4,5,6)
- **Measurements**: Pauli basis measurements (X, Y, Z) on both probe qubits
- **Circuit depth**: Shallow circuits optimized for NISQ devices

#### Single-Probe Experiments
- **Grid**: Configurable qubit arrays (3×3, 5×5, 6×6)
- **Processors**: Google Quantum AI Willow processors
- **Probe qubits**: Single-qubit systems within cluster states
- **Measurements**: Pauli basis measurements (X, Y, Z) on single probe qubit
- **Circuit depth**: Shallow circuits with ancilla-assisted error mitigation

### Machine Learning (Two-Probe Only)
- **Architecture**: Transformer (Llama-based) with quantum-specific modifications
- **Input**: Sequential quantum measurement data from two probe qubits
- **Output**: 4×4 complex quantum density matrices (two-qubit systems)
- **Training**: Adam optimizer with quantum loss functions
- **Evaluation**: Quantum information metrics (Cross Entropy, Negativity, Von Neumann Entropy)

### Performance
- **Scale**: 81M training samples, 1M test samples
- **Accuracy**: Significant improvement over classical baselines
- **Hardware**: Optimized for GPU training (8GB+ recommended)
- **Speed**: Efficient batch processing with proper memory management

## Research Applications

### Two-Probe Experiments
- **Quantum State Tomography**: ML-enhanced two-qubit state reconstruction
- **Entanglement Studies**: Characterization of quantum correlations across spatial separations
- **Quantum Machine Learning**: Novel transformer architectures for quantum data
- **NISQ Algorithm Development**: Practical quantum computing applications

### Single-Probe Experiments  
- **Single-Qubit Tomography**: Direct quantum state reconstruction
- **Measurement Error Analysis**: Sensitivity testing and robustness evaluation
- **Quantum Error Correction**: Understanding decoherence in individual qubits
- **Post-Selection Protocols**: Optimization of quantum data processing

### Both Paradigms
- **Quantum Information Theory**: Fundamental studies of quantum information
- **Hardware Characterization**: Performance evaluation of quantum processors
- **Algorithm Validation**: Benchmarking quantum state reconstruction methods

## Citation

If you use this code in your research, please cite:

```bibtex
@misc{quantum_ml_2d_2025,
    title={2D Quantum Machine Learning: Transformer-Based Quantum State Prediction},
    author={[Your Name]},
    year={2025},
    howpublished={\url{https://github.com/[your-repo]/ML-MIPT}}
}
```

## Hardware Requirements

### Minimum
- 8GB GPU memory
- 32GB RAM  
- 500GB storage
- CUDA-compatible GPU

### Recommended
- 24GB+ GPU memory
- 64GB+ RAM
- 1TB+ SSD storage
- High-speed internet (for quantum hardware access)

## Troubleshooting

### Common Issues

**GPU Memory Error**:
```python
# Reduce batch size
batch_size = 500  # instead of 1000

# Reduce model size  
n_embd, n_layer = 48, 18  # instead of 96, 36
```

**Quantum Hardware Access**:
- Ensure Google Cloud credentials are properly configured
- Verify processor availability and calibration status
- Check snapshot IDs for current hardware configurations

**Training Issues**:
```python
# Resume training from specific epoch
start_epoch = N  # automatically loads checkpoint from epoch N

# Enable deterministic training
torch.manual_seed(42)
torch.backends.cudnn.deterministic = True
```

## Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Acknowledgments

- Google Quantum AI team for hardware access and support
- HuggingFace for transformer implementations
- PyTorch and Cirq development teams
- Research institutions supporting quantum computing research

---

*This project represents cutting-edge research in quantum machine learning, combining real quantum hardware experiments with advanced ML techniques for practical quantum information processing.* 