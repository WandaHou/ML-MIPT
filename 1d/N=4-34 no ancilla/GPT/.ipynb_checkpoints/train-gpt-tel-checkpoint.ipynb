{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0825a41-2749-4cd7-aca5-23e995cd52d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator import blogm, bSqc, Neg\n",
    "from Llama2 import LlamaPredictor\n",
    "import torch\n",
    "from math import prod\n",
    "from functools import reduce\n",
    "import pandas\n",
    "from utils import dtype, device, pauli, basis, torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86ee1a7-a7b8-4b18-9671-c08a589b4205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6692"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 0\n",
    "test = True\n",
    "file = f'seed{seed}'\n",
    "train_ratio = 8/9\n",
    "batch = 500\n",
    "\n",
    "mdl = LlamaPredictor(L_max=35,\n",
    "                     L=4,\n",
    "                     n_embd=12, \n",
    "                     n_layer=6, \n",
    "                     n_head=6, \n",
    "                     vocab_size=3, \n",
    "                     dropout_prob=0.0).to(device)\n",
    "total=0 # find size of the model\n",
    "for p in mdl.parameters():\n",
    "    total+=prod(p.shape)\n",
    "total#, True_fid(mdl, psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75fbbf84-c0ed-4d4a-a66c-06a80339b5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================   Train   ==================================================\n",
      "epoch:    0 | step:   99 | N:  4 | train Sqc: 1.5496 | loss: 1.4015\n",
      "epoch:    0 | step:  199 | N:  4 | train Sqc: 1.4735 | loss: 1.3947\n",
      "epoch:    0 | step:  299 | N:  4 | train Sqc: 1.4471 | loss: 1.3922\n",
      "epoch:    0 | step:  399 | N:  4 | train Sqc: 1.4336 | loss: 1.3910\n",
      "epoch:    0 | step:  499 | N:  4 | train Sqc: 1.4251 | loss: 1.3901\n",
      "epoch:    0 | step:  599 | N:  4 | train Sqc: 1.4196 | loss: 1.3896\n",
      "epoch:    0 | step:  699 | N:  4 | train Sqc: 1.4154 | loss: 1.3892\n",
      "epoch:    0 | step:  799 | N:  4 | train Sqc: 1.4120 | loss: 1.3889\n",
      "epoch:    0 | step:  899 | N:  4 | train Sqc: 1.4096 | loss: 1.3886\n",
      "epoch:    0 | step:  999 | N:  4 | train Sqc: 1.4078 | loss: 1.3885\n",
      "epoch:    0 | step:  1099 | N:  4 | train Sqc: 1.4059 | loss: 1.3882\n",
      "epoch:    0 | step:  1199 | N:  4 | train Sqc: 1.4044 | loss: 1.3881\n",
      "epoch:    0 | step:  1299 | N:  4 | train Sqc: 1.4033 | loss: 1.3880\n",
      "epoch:    0 | step:  1399 | N:  4 | train Sqc: 1.4023 | loss: 1.3879\n",
      "epoch:    0 | step:  1499 | N:  4 | train Sqc: 1.4014 | loss: 1.3878\n",
      "epoch:    0 | step:  1599 | N:  4 | train Sqc: 1.4006 | loss: 1.3877\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1600 is out of bounds for dimension 0 with size 1600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 44\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(prepseq_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     43\u001b[0m     rhoC \u001b[38;5;241m=\u001b[39m mdl(prepseq_train[i])\n\u001b[0;32m---> 44\u001b[0m     l[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain Sqc\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(bSqc(\u001b[43mrhoS_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m, rhoC)\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     45\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     46\u001b[0m     probs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbmm(torch\u001b[38;5;241m.\u001b[39mbmm(shadow_state_train[i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m), rhoC), shadow_state_train[i]\u001b[38;5;241m.\u001b[39mconj()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mreal\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1600 is out of bounds for dimension 0 with size 1600"
     ]
    }
   ],
   "source": [
    "for N in range(4, 36, 2):\n",
    "    torch.manual_seed(seed)\n",
    "    prepseq, shadow_state, rhoS = torch_data(f'../data/data_{N}na.pickle', shuffle=True)\n",
    "    train_size = int(prepseq.shape[0]*train_ratio)\n",
    "    test_size = prepseq.shape[0]-train_size\n",
    "    \n",
    "    prepseq = torch.cat([prepseq+1, torch.zeros(prepseq.shape[0],1).to(prepseq.dtype).to(device)], -1)\n",
    "    \n",
    "    prepseq_train, prepseq_test = prepseq[:train_size], prepseq[train_size:]\n",
    "    shadow_state_train, shadow_state_test = shadow_state[:train_size], shadow_state[train_size:]\n",
    "    rhoS_train, rhoS_test = rhoS[:train_size], rhoS[train_size:]\n",
    "    \n",
    "    # split in batches\n",
    "    prepseq_train = prepseq_train.view(-1, batch, N-2)\n",
    "    shadow_state_train = shadow_state_train.view(-1, batch, 4)\n",
    "    rhoS_train = rhoS_train.view(-1, batch, 4, 4)\n",
    "\n",
    "    prepseq_test = prepseq_test.view(-1, batch, N-2)\n",
    "    shadow_state_test = shadow_state_test.view(-1, batch, 4)\n",
    "    rhoS_test = rhoS_test.view(-1, batch, 4, 4)\n",
    "    \n",
    "    mdl = LlamaPredictor(L_max=35,\n",
    "                     L=prepseq_train.shape[1]-1,\n",
    "                     n_embd=12, \n",
    "                     n_layer=6, \n",
    "                     n_head=6, \n",
    "                     vocab_size=3, \n",
    "                     dropout_prob=0.0).to(device)\n",
    "    # load new model\n",
    "    if N > 4:\n",
    "        mdl.load_state_dict(torch.load(f'{file}/models/mpo_N={N-2}_na.pt'))\n",
    "    # load old model\n",
    "    # mdl.load_state_dict(torch.load(f'{file}/models/mpo_N={N}_na.pt'))\n",
    "    \n",
    "    optimizer = torch.optim.Adam(mdl.parameters(), lr=1e-3) # 0.0001\n",
    "    l = {'train Sqc':[], 'test Sqc':[], 'test Neg':[], 'loss':[]}\n",
    "    \n",
    "    for epoch in range(5):\n",
    "        # Train\n",
    "        print('='*50+'   Train   '+'='*50)\n",
    "        mdl.train()\n",
    "        for i in range(prepseq_train.shape[0]):\n",
    "            rhoC = mdl(prepseq_train[i])\n",
    "            l['train Sqc'].append(bSqc(rhoS_train[i], rhoC).mean().item())\n",
    "            optimizer.zero_grad()\n",
    "            probs = torch.bmm(torch.bmm(shadow_state_train[i].unsqueeze(1), rhoC), shadow_state_train[i].conj().unsqueeze(-1)).view(-1).real\n",
    "            loss = -probs.log().mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            l['loss'].append(loss.item())\n",
    "            if (i+1)%100 == 0:\n",
    "                trainS = torch.tensor(l['train Sqc'])[-i:].mean().item()\n",
    "                loss = torch.tensor(l['loss'])[-i:].mean().item()\n",
    "                print('epoch:  %3d | step:  %3d | N:  %d | train Sqc: %.4f | loss: %.4f' %(epoch, i, N, trainS, loss))\n",
    "        # Test\n",
    "        if test:\n",
    "            with torch.no_grad():\n",
    "                print('='*50+'   Test   '+'='*50)\n",
    "                mdl.eval()\n",
    "                for i in range(prepseq_test.shape[0]):\n",
    "                    rhoC = mdl(prepseq_test[i])\n",
    "                    l['test Sqc'].append(bSqc(rhoS_test[i], rhoC).mean().item())\n",
    "                    l['test Neg'].append(Neg(rhoS_test[i], rhoC).mean().item())\n",
    "                    if (i+1)%100 == 0:\n",
    "                        testS = torch.tensor(l['test Sqc'])[-i:].mean().item()\n",
    "                        testN = torch.tensor(l['test Neg'])[-i:].mean().item()\n",
    "                        print('epoch:  %3d | step:  %3d | N:  %d | test Sqc: %.4f | test Neg: %.4f' %(epoch, i, N, testS, testN))\n",
    "        torch.save(l, f'{file}/record/gpt_N={N}_na.pt')\n",
    "        torch.save(mdl.state_dict(), f'{file}/models/gpt_N={N}_na.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d432cd1f-ac10-4812-845e-19e3555c413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2400, 500, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepseq_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd304a4-53cc-469a-a5d0-1e79de9dcabf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
